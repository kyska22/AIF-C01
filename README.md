# Semana 1: Fundamentos de AI/ML y Generative AI

## Día 1: Introducción a la Inteligencia Artificial y el Aprendizaje Automático (AI/ML)
- Repasar conceptos básicos de AI/ML:
  - Definiciones de AI, ML, Deep Learning, redes neuronales, visión por computadora, NLP.
  - Tipos de aprendizaje (supervisado, no supervisado, refuerzo).
  - Diferencias entre AI, ML y Deep Learning.
  - Leer sobre los tipos de datos en modelos de AI: datos etiquetados, no etiquetados, tabulares, texto, etc.

## Día 2: Casos de uso de AI/ML
- Identificar aplicaciones prácticas de AI/ML (por ejemplo, sistemas de recomendación, detección de fraude).
- Analizar cuándo no es adecuado usar AI/ML.
- Estudiar servicios AWS para AI/ML: SageMaker, Amazon Comprehend, Polly, Lex, Translate, etc.

## Día 3: Ciclo de desarrollo de modelos ML
- Componentes clave de un pipeline ML (colección de datos, preprocesamiento, entrenamiento, despliegue).
- Servicios AWS relacionados (SageMaker Feature Store, Model Monitor, Data Wrangler).

## Día 4: Introducción a Generative AI
- Conceptos básicos: modelos fundacionales, embeddings, transformers, engineering de prompts.
- Casos de uso: generación de imágenes, chatbots, traducción, motores de búsqueda.

## Día 5: Infraestructura para Generative AI en AWS
- Servicios de AWS: Amazon Bedrock, JumpStart, Q, SageMaker.
- Ventajas y limitaciones de AWS para aplicaciones generativas (costos, escalabilidad, seguridad).

---

# Semana 2: Aplicaciones de Modelos Fundacionales

## Día 6: Diseño de aplicaciones con modelos fundacionales
- Selección de modelos pre-entrenados (criterios: costo, latencia, tamaño).
- Parámetros de inferencia: temperatura, longitud de entrada/salida.

## Día 7: Engineering de prompts
- Técnicas clave: cadena de pensamiento, few-shot, zero-shot.
- Mejores prácticas para ingeniería de prompts.

## Día 8: Proceso de ajuste fino
- Elementos de entrenamiento: pre-entrenamiento, ajuste fino.
- Preparación de datos para ajuste fino (curación, etiquetado, representatividad).

## Día 9: Evaluación de modelos fundacionales
- Métodos de evaluación: métricas (ROUGE, BLEU, BERTScore).
- Cómo determinar si un modelo cumple objetivos de negocio.

## Día 10: Práctica con servicios AWS
- Explorar Bedrock y SageMaker para personalizar modelos fundacionales.

---

# Semana 3: AI Responsable y Seguridad

## Día 11: AI Responsable
- Características: equidad, seguridad, robustez, veracidad.
- Herramientas de AWS para AI Responsable (SageMaker Clarify, A2I, Model Monitor).

## Día 12: Transparencia y explicabilidad
- Diferencias entre modelos transparentes y no transparentes.
- Principios de diseño centrado en el usuario para AI explicable.

## Día 13: Seguridad de sistemas de AI
- Métodos para asegurar sistemas (cifrado, IAM, Macie, PrivateLink).
- Consideraciones de privacidad y seguridad de datos.

## Día 14: Gobernanza y cumplimiento
- Normativas clave: ISO, SOC.
- Servicios AWS para cumplimiento: Config, Audit Manager, Artifact.

## Día 15: Estrategias de gobernanza
- Gestión de ciclo de vida de datos, retención, monitoreo.

---

# Semana 4: Revisión y Simulación de Examen

## Día 16: Repaso de fundamentos
- Revisar conceptos clave de AI/ML y Generative AI.
- Enfocarse en el ciclo de vida de desarrollo y casos de uso.

## Día 17: Repaso de aplicaciones de modelos fundacionales
- Reforzar prompts y ajustes finos.
- Evaluación y métricas.

## Día 18: Repaso de AI Responsable y Seguridad
- Revisión de herramientas de monitoreo, gobernanza y seguridad.

## Día 19: Simulación de examen
- Resolver preguntas de práctica basadas en los dominios del examen.
- Analizar resultados y reforzar áreas débiles.

## Día 20: Revisión final
- Repaso rápido de notas, puntos débiles y conceptos clave.

